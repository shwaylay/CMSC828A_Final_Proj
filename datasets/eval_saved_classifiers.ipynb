{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, folder_nolayoff, folder_layoff, src_col):\n",
    "        \n",
    "        # csvs_layoffs = glob.glob(folder_layoff + \"/*.csv\")\n",
    "        # csvs_nolayoffs = glob.glob(folder_nolayoff + \"/*.csv\")\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        all_csv_files = []\n",
    "        EXT = \"*.csv\"  # Define the variable EXT\n",
    "        for path, subdir, files in os.walk(folder_layoff):\n",
    "            \n",
    "            for file in glob(os.path.join(path, EXT)):\n",
    "                # print(file)\n",
    "                df = pd.read_csv(file, index_col=0, parse_dates=True).sort_index()\n",
    "                ## If length of dataset is over 90, then cut it to 90\n",
    "                if len(df) > 90:\n",
    "                    print(\"OVER LENGTH\", file)\n",
    "                    df = df[-90:]\n",
    "                ## If length of dataset is less than 90, then skip it\n",
    "                if len(df) < 90:\n",
    "                    continue\n",
    "                X_train.append(df[src_col].values)\n",
    "                Y_train.append(float(1))\n",
    "                # all_csv_files.append(file)\n",
    "\n",
    "        for path, subdir, files in os.walk(folder_nolayoff):\n",
    "            for file in glob(os.path.join(path, EXT)):\n",
    "                df = pd.read_csv(file, index_col=0, parse_dates=True).sort_index()\n",
    "                ## If length of dataset is over 90, then cut it to 90\n",
    "                if len(df) > 90:\n",
    "                    print(\"OVER LENGTH\", file)\n",
    "                    df = df[-90:]\n",
    "\n",
    "                ## If length of dataset is less than 90, then skip it\n",
    "                if len(df) < 90:\n",
    "                    continue\n",
    "                X_train.append(df[src_col].values)\n",
    "                Y_train.append(float(0))\n",
    "        X_train = torch.from_numpy(np.array(X_train))\n",
    "        Y_train = torch.from_numpy(np.array(Y_train))\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.num_channels = X_train.shape[1]\n",
    "        self.len = X_train.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx].float(), self.Y_train[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDatasetEval(Dataset):\n",
    "    def __init__(self, folder, src_col):\n",
    "        \n",
    "        # csvs_layoffs = glob.glob(folder_layoff + \"/*.csv\")\n",
    "        # csvs_nolayoffs = glob.glob(folder_nolayoff + \"/*.csv\")\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        all_csv_files = []\n",
    "        EXT = \"*.csv\"  # Define the variable EXT\n",
    "        for path, subdir, files in os.walk(folder):\n",
    "            \n",
    "            for file in glob(os.path.join(path, EXT)):\n",
    "                # print(file)\n",
    "                df = pd.read_csv(file, index_col=0, parse_dates=True).sort_index()\n",
    "                ## If length of dataset is over 90, then cut it to 90\n",
    "                if len(df) > 90:\n",
    "                    print(\"OVER LENGTH\", file)\n",
    "                    df = df[-90:]\n",
    "                ## If length of dataset is less than 90, then skip it\n",
    "                if len(df) < 90:\n",
    "                    continue\n",
    "                X_train.append(df[src_col].values)\n",
    "                if \"layoff\" in folder:\n",
    "                    Y_train.append(float(1))\n",
    "                else:\n",
    "                    Y_train.append(float(0))\n",
    "                # all_csv_files.append(file)\n",
    "\n",
    "        X_train = torch.from_numpy(np.array(X_train))\n",
    "        Y_train = torch.from_numpy(np.array(Y_train))\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.num_channels = X_train.shape[1]\n",
    "        self.len = X_train.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx].float(), self.Y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_real_layoffs_minmax = TimeSeriesDatasetEval(folder = \"chronos_stocks_layoffs/real\", src_col = \"Scaled_Price_MinMax\")\n",
    "dataloader_real_layoffs_oipa = TimeSeriesDatasetEval(folder = \"chronos_stocks_layoffs/real\", src_col = \"open_inproportion_to_average\")\n",
    "dataloader_real_layoffs_on = TimeSeriesDatasetEval(folder = \"chronos_stocks_layoffs/real\", src_col = \"open_normalized\")\n",
    "dataloader_real_nolayoffs_on =  TimeSeriesDatasetEval(folder = \"chronos_stocks_nolayoffs/real\", src_col = \"open_normalized\")\n",
    "dataloader_real_nolayoffs_minmax = TimeSeriesDatasetEval(folder = \"chronos_stocks_nolayoffs/real\", src_col = \"Scaled_Price_MinMax\")\n",
    "dataloader_real_nolayoffs_oipa = TimeSeriesDatasetEval(folder = \"chronos_stocks_nolayoffs/real\", src_col = \"open_inproportion_to_average\")\n",
    "dataloader_chronos_layoffs_minmax = TimeSeriesDatasetEval(folder = \"chronos_stocks_layoffs/chronos\", src_col = \"Scaled_Price_MinMax\")\n",
    "dataloader_chronos_layoffs_oipa = TimeSeriesDatasetEval(folder = \"chronos_stocks_layoffs/chronos\", src_col = \"median_inproportion_to_average\")\n",
    "dataloader_chronos_layoffs_on = TimeSeriesDatasetEval(folder = \"chronos_stocks_layoffs/chronos\", src_col = \"median_normalized\")\n",
    "dataloader_chronos_nolayoffs_minmax = TimeSeriesDatasetEval(folder = \"chronos_stocks_nolayoffs/chronos\", src_col = \"Scaled_Price_MinMax\")\n",
    "dataloader_chronos_nolayoffs_oipa = TimeSeriesDatasetEval(folder = \"chronos_stocks_nolayoffs/chronos\", src_col = \"median_inproportion_to_average\")\n",
    "dataloader_chronos_nolayoffs_on = TimeSeriesDatasetEval(folder = \"chronos_stocks_nolayoffs/chronos\", src_col = \"median_normalized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_chronos_layoffs_minmax = torch.utils.data.DataLoader(dataloader_chronos_layoffs_minmax, batch_size=1, shuffle=False)\n",
    "dataloader_chronos_layoffs_oipa = torch.utils.data.DataLoader(dataloader_chronos_layoffs_oipa, batch_size=1, shuffle=False)\n",
    "dataloader_chronos_layoffs_on = torch.utils.data.DataLoader(dataloader_chronos_layoffs_on, batch_size=1, shuffle=False)\n",
    "dataloader_chronos_nolayoffs_minmax = torch.utils.data.DataLoader(dataloader_chronos_nolayoffs_minmax, batch_size=1, shuffle=False)\n",
    "dataloader_chronos_nolayoffs_oipa = torch.utils.data.DataLoader(dataloader_chronos_nolayoffs_oipa, batch_size=1, shuffle=False)\n",
    "dataloader_chronos_nolayoffs_on = torch.utils.data.DataLoader(dataloader_chronos_nolayoffs_on, batch_size=1, shuffle=False)\n",
    "dataloader_real_layoffs_minmax = torch.utils.data.DataLoader(dataloader_real_layoffs_minmax, batch_size=1, shuffle=False)\n",
    "dataloader_real_layoffs_oipa = torch.utils.data.DataLoader(dataloader_real_layoffs_oipa, batch_size=1, shuffle=False)\n",
    "dataloader_real_layoffs_on = torch.utils.data.DataLoader(dataloader_real_layoffs_on, batch_size=1, shuffle=False)\n",
    "dataloader_real_nolayoffs_on = torch.utils.data.DataLoader(dataloader_real_nolayoffs_on, batch_size=1, shuffle=False)\n",
    "dataloader_real_nolayoffs_minmax = torch.utils.data.DataLoader(dataloader_real_nolayoffs_minmax, batch_size=1, shuffle=False)\n",
    "dataloader_real_nolayoffs_oipa = torch.utils.data.DataLoader(dataloader_real_nolayoffs_oipa, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228, 90])\n"
     ]
    }
   ],
   "source": [
    "print(dataloader_real_nolayoffs_minmax.dataset.X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228, 90])\n"
     ]
    }
   ],
   "source": [
    "print(dataloader_chronos_nolayoffs_minmax.dataset.X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260, 90])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_chronos_layoffs_minmax.dataset.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([260, 90])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_real_layoffs_minmax.dataset.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stocks_layoffs/Energy/ENPH0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_min = list(df['Open'].rolling(window=90).min())[-1]\n",
    "rolling_max = list(df['Open'].rolling(window=90).max())[-1]\n",
    "\n",
    "# Calculate the scaled prices\n",
    "df['Scaled_Price_MinMax'] = (df[\"Open\"] - rolling_min) / (rolling_max - rolling_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg = list(df['Open'].rolling(window=90).mean())[-1]\n",
    "# df['Normalized_Price_minmax'] = df['Open'] / avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Normalized_Price_minmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_minmax = TimeSeriesDataset(\"stocks_no_layoffs\", \"stocks_layoffs\", \"Scaled_Price_MinMax\")\n",
    "# dataset_oipa = TimeSeriesDataset(\"stocks_no_layoffs\", \"stocks_layoffs\", \"open_inproportion_to_average\")\n",
    "# dataset_on = TimeSeriesDataset(\"stocks_no_layoffs\", \"stocks_layoffs\", \"open_normalized\")\n",
    "# batch_size = 1\n",
    "# validation_split = .2\n",
    "# shuffle_dataset = True\n",
    "# random_seed= 42\n",
    "\n",
    "# # Creating data indices for training and validation splits:\n",
    "# dataset_size = len(dataset_minmax)\n",
    "# indices = list(range(dataset_size))\n",
    "# split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "# train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# # Creating PT data samplers and loaders:\n",
    "# train_sampler = SubsetRandomSampler(train_indices)\n",
    "# valid_sampler = SequentialSampler(val_indices)\n",
    "\n",
    "# train_loader_minmax = torch.utils.data.DataLoader(dataset_minmax, batch_size=batch_size, \n",
    "#                                            sampler=train_sampler)\n",
    "# train_loader_oipa = torch.utils.data.DataLoader(dataset_oipa, batch_size=batch_size, \n",
    "#                                            sampler=train_sampler)\n",
    "# train_loader_on = torch.utils.data.DataLoader(dataset_on, batch_size=batch_size, \n",
    "#                                            sampler=train_sampler)\n",
    "\n",
    "# validation_loader_minmax = torch.utils.data.DataLoader(dataset_minmax, batch_size=batch_size, sampler=valid_sampler)\n",
    "# validation_loader_oipa = torch.utils.data.DataLoader(dataset_oipa, batch_size=batch_size, sampler=valid_sampler)\n",
    "# validation_loader_on = torch.utils.data.DataLoader(dataset_on, batch_size=batch_size,   sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader_minmax.dataset.Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(90, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model_minmax = BinaryClassifier()\n",
    "model_open_inproportion_to_average = BinaryClassifier()\n",
    "model_open_normalized = BinaryClassifier()\n",
    "#Load in the saved models \n",
    "model_minmax.load_state_dict(torch.load(\"classifier_models/minmax_model.pth\"))\n",
    "model_open_inproportion_to_average.load_state_dict(torch.load(\"classifier_models/open_inproportion_to_average_model.pth\"))\n",
    "model_open_normalized.load_state_dict(torch.load(\"classifier_models/open_normalized_model.pth\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single model eval\n",
    "# is_correct = []\n",
    "# for i, (X_train, y_train) in enumerate(validation_loader_minmax):\n",
    "    \n",
    "\n",
    "#         # print(X_train)\n",
    "#         # print(y_train)\n",
    "#         # Forward pass\n",
    "#     outputs = model(X_train)\n",
    "#     out = outputs.squeeze(1)\n",
    "#     output_bin = (out >= 0.5).int().item()\n",
    "#     correct = output_bin == int(0.0)\n",
    "#     is_correct.append(correct)\n",
    "# # Count ratio of trues and falses in is_correct\n",
    "# true_count = sum(is_correct)\n",
    "# false_count = len(is_correct) - true_count\n",
    "# print(f\"True count: {true_count}\")\n",
    "# print(f\"False count: {false_count}\")\n",
    "# print(f\"True ratio: {true_count / len(is_correct)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval on nolayoff data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ratio (Confidence) (Chronos): 0.5263157894736842\n",
      "True ratio (Vote) (Chronos): 0.4868421052631579\n",
      "True ratio (minmax) (Chronos): 0.5307017543859649\n",
      "True ratio (OIPA) (Chronos): 0.0\n",
      "True ratio (ON) (Chronos): 0.9035087719298246\n",
      "True ratio (Confidence) (Real): 0.7543859649122807\n",
      "True ratio (Vote) (Real): 0.7412280701754386\n",
      "True ratio (minmax) (Real): 0.7543859649122807\n",
      "True ratio (OIPA) (Real): 0.05263157894736842\n",
      "True ratio (ON) (Real): 0.9254385964912281\n",
      "True ratio (Matching Vote): 0.49122807017543857\n",
      "True ratio (Matching Confidence): 0.5350877192982456\n",
      "True ratio (Matching Minmax): 0.5394736842105263\n",
      "True ratio (Matching OIPA): 0.9473684210526315\n",
      "True ratio (Matching ON): 0.8289473684210527\n"
     ]
    }
   ],
   "source": [
    "# Majority Voting Ensemble Eval\n",
    "is_correct_confidence_chronos = []\n",
    "f1_score_confidence_chronos = []\n",
    "is_correct_vote_chronos = []\n",
    "is_correct_minmax_chronos = []\n",
    "is_correct_oipa_chronos = []\n",
    "is_correct_on_chronos = []\n",
    "\n",
    "is_correct_confidence_real = []\n",
    "\n",
    "is_correct_vote_real = []\n",
    "is_correct_minmax_real = []\n",
    "is_correct_oipa_real = []\n",
    "is_correct_on_real = []\n",
    "is_matching_vote = []\n",
    "is_matching_confidence = []\n",
    "is_matching_minmax = []\n",
    "is_matching_oipa = []\n",
    "is_matching_on = []\n",
    "\n",
    "# is_correct_vote = []\n",
    "# is_correct_minmax = []\n",
    "# is_correct_oipa = []\n",
    "# is_correct_on = []\n",
    "\n",
    "for i, (X_train, y_train) in enumerate(dataloader_chronos_nolayoffs_minmax):\n",
    "        # print(X_train)\n",
    "        # print(y_train)\n",
    "        # Forward pass\n",
    "    \n",
    "    X_train_minmax_chronos = dataloader_chronos_nolayoffs_minmax.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_oipa_chronos = dataloader_chronos_nolayoffs_oipa.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_on_chronos = dataloader_chronos_nolayoffs_on.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_minmax_real = dataloader_real_nolayoffs_minmax.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_oipa_real = dataloader_real_nolayoffs_oipa.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_on_real = dataloader_real_nolayoffs_on.dataset.X_train[i].unsqueeze(0).float()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # print(outputs_minmax)\n",
    "    outputs_minmax_chronos = model_minmax(X_train_minmax_chronos).squeeze(1)\n",
    "    outputs_oipa_chronos = model_open_inproportion_to_average(X_train_oipa_chronos).squeeze(1)\n",
    "    outputs_on_chronos = model_open_normalized(X_train_on_chronos).squeeze(1)\n",
    "    outputs_minmax_real = model_minmax(X_train_minmax_real).squeeze(1)\n",
    "    outputs_oipa_real = model_open_inproportion_to_average(X_train_oipa_real).squeeze(1)\n",
    "    outputs_on_real = model_open_normalized(X_train_on_real).squeeze(1)\n",
    "\n",
    "    \n",
    "\n",
    "    ## Ensemble confidence based on average of outputs\n",
    "    confidence_avg_out_chronos = ( outputs_minmax_chronos+ outputs_oipa_chronos) / 2\n",
    "    confidence_output_bin_chronos = (confidence_avg_out_chronos >= 0.5).int().item()\n",
    "    confidence_avg_out_real = (outputs_minmax_real + outputs_oipa_real) / 2\n",
    "    confidence_output_bin_real = (confidence_avg_out_real >= 0.5).int().item()\n",
    "    \n",
    "    ## Ensemble voting based on majority voting\n",
    "    vote_minmax_chronos = (outputs_minmax_chronos >= 0.5).int().item()\n",
    "    is_correct_minmax_chronos.append(vote_minmax_chronos == int(0.0))\n",
    "    vote_oipa_chronos = (outputs_oipa_chronos >= 0.5).int().item()\n",
    "    is_correct_oipa_chronos.append(vote_oipa_chronos == int(0.0))\n",
    "    vote_on_chronos = (outputs_on_chronos >= 0.5).int().item()\n",
    "    is_correct_on_chronos.append(vote_on_chronos == int(0.0))\n",
    "    \n",
    "    vote_minmax_real = (outputs_minmax_real >= 0.5).int().item()\n",
    "    is_correct_minmax_real.append(vote_minmax_real == int(0.0))\n",
    "    vote_oipa_real = (outputs_oipa_real >= 0.5).int().item()\n",
    "    is_correct_oipa_real.append(vote_oipa_real == int(0.0))\n",
    "    vote_on_real = (outputs_on_real >= 0.5).int().item()\n",
    "    is_correct_on_real.append(vote_on_real == int(0.0))\n",
    "\n",
    "    ## Ensemble voting based on majority voting\n",
    "    vote_chronos = (vote_minmax_chronos+vote_oipa_chronos + vote_on_chronos) >= 2\n",
    "    correct_confidence = confidence_output_bin_chronos == int(0.0)\n",
    "    correct_vote = vote_chronos == int(0.0)\n",
    "    is_correct_confidence_chronos.append(correct_confidence)\n",
    "    is_correct_vote_chronos.append(correct_vote)\n",
    "\n",
    "    vote_real = (vote_minmax_real + vote_oipa_real + vote_on_real) >= 2\n",
    "    correct_confidence_real = confidence_output_bin_real == int(0.0)\n",
    "    correct_vote_real = vote_real == int(0.0)\n",
    "    is_correct_confidence_real.append(correct_confidence_real)\n",
    "    is_correct_vote_real.append(correct_vote_real)\n",
    "\n",
    "    is_matching_vote.append(vote_chronos == vote_real)\n",
    "    is_matching_confidence.append(confidence_output_bin_chronos == confidence_output_bin_real)\n",
    "    is_matching_minmax.append(vote_minmax_chronos == vote_minmax_real)\n",
    "    is_matching_oipa.append(vote_oipa_chronos == vote_oipa_real)\n",
    "    is_matching_on.append(vote_on_chronos == vote_on_real)\n",
    "\n",
    "    # out = outputs.squeeze(1)\n",
    "    # output_bin = (out >= 0.5).int().item()\n",
    "    # correct = output_bin == int(y_train.item())\n",
    "    # is_correct.append(correct)\n",
    "# Count ratio of trues and falses in is_correct\n",
    "with open(\"outputs_nolayoffs_5.txt\", \"w\") as f:\n",
    "    chronos_f1_prepro_nolayoff = [0 if i == False else 1 for i in is_correct_confidence_chronos]\n",
    "    chronos_f1_true_nolayoff = [0 for i in is_correct_confidence_chronos]\n",
    "    # f1 = f1_score(chronos_f1_prepro, chronos_f1_true, pos_label=0, average=\"binary\")\n",
    "    # print(f\"F1 Score (Confidence) (Chronos): {f1}\")\n",
    "    # f.write(f\"F1 Score (Confidence) (Chronos): {f1}\\n\")\n",
    "    real_f1_prepro_nolayoffs = [0 if i == False else 1 for i in is_correct_confidence_real]\n",
    "    real_f1_true_nolayoffs = [0 for i in is_correct_confidence_real]\n",
    "    # f1 = f1_score(real_f1_prepro, real_f1_true, pos_label=0, average=\"binary\")\n",
    "    # print(f\"F1 Score (Confidence) (Real): {f1}\")\n",
    "    # f.write(f\"F1 Score (Confidence) (Real): {f1}\\n\")\n",
    "    true_count_confidence_chronos = sum(is_correct_confidence_chronos)\n",
    "    false_count_confidence_chronos = len(is_correct_confidence_chronos) - true_count_confidence_chronos\n",
    "    # print(f\"True count (Confidence) (Chronos): {true_count_confidence_chronos}\")\n",
    "    # print(f\"False count (Confidence) (Chronos): {false_count_confidence_chronos}\")\n",
    "    print(f\"True ratio (Confidence) (Chronos): {true_count_confidence_chronos / len(is_correct_confidence_chronos)}\")\n",
    "    f.write(f\"True ratio (Confidence) (Chronos): {true_count_confidence_chronos / len(is_correct_confidence_chronos)}\\n\")\n",
    "    true_count_vote_chronos = sum(is_correct_vote_chronos)\n",
    "    false_count_vote_chronos = len(is_correct_vote_chronos) - true_count_vote_chronos\n",
    "    # print(f\"True count (Vote) (Chronos): {true_count_vote_chronos}\")\n",
    "    # print(f\"False count (Vote) (Chronos): {false_count_vote_chronos}\")\n",
    "    print(f\"True ratio (Vote) (Chronos): {true_count_vote_chronos / len(is_correct_vote_chronos)}\")\n",
    "    f.write(f\"True ratio (Vote) (Chronos): {true_count_vote_chronos / len(is_correct_vote_chronos)}\\n\")\n",
    "    true_count_minmax_chronos = sum(is_correct_minmax_chronos)\n",
    "    false_count_minmax_chronos = len(is_correct_minmax_chronos) - true_count_minmax_chronos\n",
    "    # print(f\"True count (minmax) (Chronos): {true_count_minmax_chronos}\")\n",
    "    # print(f\"False count (minmax) (Chronos): {false_count_minmax_chronos}\")\n",
    "    print(f\"True ratio (minmax) (Chronos): {true_count_minmax_chronos / len(is_correct_minmax_chronos)}\")\n",
    "    f.write(f\"True ratio (minmax) (Chronos): {true_count_minmax_chronos / len(is_correct_minmax_chronos)}\\n\")\n",
    "    true_count_oipa_chronos = sum(is_correct_oipa_chronos)\n",
    "    false_count_oipa_chronos = len(is_correct_oipa_chronos) - true_count_oipa_chronos\n",
    "\n",
    "    print(f\"True ratio (OIPA) (Chronos): {true_count_oipa_chronos / len(is_correct_oipa_chronos)}\")\n",
    "    f.write(f\"True ratio (OIPA) (Chronos): {true_count_oipa_chronos / len(is_correct_oipa_chronos)}\\n\")\n",
    "    true_count_on_chronos = sum(is_correct_on_chronos)\n",
    "    false_count_on_chronos = len(is_correct_on_chronos) - true_count_on_chronos\n",
    "    print(f\"True ratio (ON) (Chronos): {true_count_on_chronos / len(is_correct_on_chronos)}\")\n",
    "    f.write(f\"True ratio (ON) (Chronos): {true_count_on_chronos / len(is_correct_on_chronos)}\\n\")\n",
    "\n",
    "\n",
    "    true_count_confidence_real = sum(is_correct_confidence_real)\n",
    "    false_count_confidence_real = len(is_correct_confidence_real) - true_count_confidence_real\n",
    "    # print(f\"True count (Confidence) (Real): {true_count_confidence_real}\")\n",
    "    # print(f\"False count (Confidence) (Real): {false_count_confidence_real}\")\n",
    "    print(f\"True ratio (Confidence) (Real): {true_count_confidence_real / len(is_correct_confidence_real)}\")\n",
    "    f.write(f\"True ratio (Confidence) (Real): {true_count_confidence_real / len(is_correct_confidence_real)}\\n\")\n",
    "    true_count_vote_real = sum(is_correct_vote_real)\n",
    "    false_count_vote_real = len(is_correct_vote_real) - true_count_vote_real\n",
    "    # print(f\"True count (Vote) (Real): {true_count_vote_real}\")\n",
    "    # print(f\"False count (Vote) (Real): {false_count_vote_real}\")\n",
    "    print(f\"True ratio (Vote) (Real): {true_count_vote_real / len(is_correct_vote_real)}\")\n",
    "    f.write(f\"True ratio (Vote) (Real): {true_count_vote_real / len(is_correct_vote_real)}\\n\")\n",
    "    true_count_minmax_real = sum(is_correct_minmax_real)\n",
    "    false_count_minmax_real = len(is_correct_minmax_real) - true_count_minmax_real\n",
    "    # print(f\"True count (minmax) (Real): {true_count_minmax_real}\")\n",
    "    # print(f\"False count (minmax) (Real): {false_count_minmax_real}\")\n",
    "    print(f\"True ratio (minmax) (Real): {true_count_minmax_real / len(is_correct_minmax_real)}\")\n",
    "    f.write(f\"True ratio (minmax) (Real): {true_count_minmax_real / len(is_correct_minmax_real)}\\n\")\n",
    "    true_count_oipa_real = sum(is_correct_oipa_real)\n",
    "    false_count_oipa_real = len(is_correct_oipa_real) - true_count_oipa_real\n",
    "    # print(f\"True count (OIPA) (Real): {true_count_oipa_real}\")\n",
    "    # print(f\"False count (OIPA) (Real): {false_count_oipa_real}\")\n",
    "    print(f\"True ratio (OIPA) (Real): {true_count_oipa_real / len(is_correct_oipa_real)}\")\n",
    "    f.write(f\"True ratio (OIPA) (Real): {true_count_oipa_real / len(is_correct_oipa_real)}\\n\")\n",
    "    true_count_on_real = sum(is_correct_on_real)\n",
    "    false_count_on_real = len(is_correct_on_real) - true_count_on_real\n",
    "    # print(f\"True count (ON) (Real): {true_count_on_real}\")\n",
    "    # print(f\"False count (ON) (Real): {false_count_on_real}\")\n",
    "    print(f\"True ratio (ON) (Real): {true_count_on_real / len(is_correct_on_real)}\")\n",
    "    f.write(f\"True ratio (ON) (Real): {true_count_on_real / len(is_correct_on_real)}\\n\")\n",
    "\n",
    "    true_count_matching_vote = sum(is_matching_vote)\n",
    "    false_count_matching_vote = len(is_matching_vote) - true_count_matching_vote\n",
    "    print(f\"True ratio (Matching Vote): {true_count_matching_vote / len(is_matching_vote)}\")\n",
    "    f.write(f\"True ratio (Matching Vote): {true_count_matching_vote / len(is_matching_vote)}\\n\")\n",
    "    true_count_matching_confidence = sum(is_matching_confidence)\n",
    "    false_count_matching_confidence = len(is_matching_confidence) - true_count_matching_confidence\n",
    "    print(f\"True ratio (Matching Confidence): {true_count_matching_confidence / len(is_matching_confidence)}\")\n",
    "    f.write(f\"True ratio (Matching Confidence): {true_count_matching_confidence / len(is_matching_confidence)}\\n\")\n",
    "    true_count_matching_minmax = sum(is_matching_minmax)\n",
    "    false_count_matching_minmax = len(is_matching_minmax) - true_count_matching_minmax\n",
    "    print(f\"True ratio (Matching Minmax): {true_count_matching_minmax / len(is_matching_minmax)}\")\n",
    "    f.write(f\"True ratio (Matching Minmax): {true_count_matching_minmax / len(is_matching_minmax)}\\n\")\n",
    "    true_count_matching_oipa = sum(is_matching_oipa)\n",
    "    false_count_matching_oipa = len(is_matching_oipa) - true_count_matching_oipa\n",
    "    print(f\"True ratio (Matching OIPA): {true_count_matching_oipa / len(is_matching_oipa)}\")\n",
    "    f.write(f\"True ratio (Matching OIPA): {true_count_matching_oipa / len(is_matching_oipa)}\\n\")\n",
    "    true_count_matching_on = sum(is_matching_on)\n",
    "    false_count_matching_on = len(is_matching_on) - true_count_matching_on\n",
    "    print(f\"True ratio (Matching ON): {true_count_matching_on / len(is_matching_on)}\")\n",
    "    f.write(f\"True ratio (Matching ON): {true_count_matching_on / len(is_matching_on)}\\n\")\n",
    "\n",
    "f.close()\n",
    "    # print(f\"True count (OIPA) (Chronos): {true_count_oipa_chronos}\")\n",
    "    # print(f\"False count (OIPA) (Chronos): {false_count_oipa_chronos}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# true_count_confidence = sum(is_correct_confidence)\n",
    "# false_count_confidence = len(is_correct_confidence) - true_count_confidence\n",
    "# print(f\"True count (Confidence): {true_count_confidence}\")\n",
    "# print(f\"False count (Confidence): {false_count_confidence}\")\n",
    "# print(f\"True ratio (Confidence): {true_count_confidence / len(is_correct_confidence)}\")\n",
    "# true_count_vote = sum(is_correct_vote)\n",
    "# false_count_vote = len(is_correct_vote) - true_count_vote\n",
    "# print(f\"True count (Vote): {true_count_vote}\")\n",
    "# print(f\"False count (Vote): {false_count_vote}\")\n",
    "# print(f\"True ratio (Vote): {true_count_vote / len(is_correct_vote)}\")\n",
    "# true_count_minmax = sum(is_correct_minmax)\n",
    "# false_count_minmax = len(is_correct_minmax) - true_count_minmax\n",
    "# print(f\"True count (minmax): {true_count_minmax}\")\n",
    "# print(f\"False count (minmax): {false_count_minmax}\")\n",
    "# print(f\"True ratio (minmax): {true_count_minmax / len(is_correct_minmax)}\")\n",
    "# true_count_oipa = sum(is_correct_oipa)\n",
    "# false_count_oipa = len(is_correct_oipa) - true_count_oipa\n",
    "# print(f\"True count (OIPA): {true_count_oipa}\")\n",
    "# print(f\"False count (OIPA): {false_count_oipa}\")\n",
    "# print(f\"True ratio (OIPA): {true_count_oipa / len(is_correct_oipa)}\")\n",
    "# true_count_on = sum(is_correct_on)\n",
    "# false_count_on = len(is_correct_on) - true_count_on\n",
    "# print(f\"True count (ON): {true_count_on}\")\n",
    "# print(f\"False count (ON): {false_count_on}\")\n",
    "# print(f\"True ratio (ON): {true_count_on / len(is_correct_on)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval on Layoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is correct real [True, True, False, True, True, False, False, True, True, False, True, False, False, True, True, True, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, False, False, True, False, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, False, True, True, True, False, False, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, False, False, True, True, True, False, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True, False, False, True, False, False, False, True, True, True, True, True, False, True, False, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, False, True, False, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True]\n",
      "True ratio (Confidence) (Chronos): 0.5153846153846153\n",
      "True ratio (Vote) (Chronos): 0.09615384615384616\n",
      "True ratio (minmax) (Chronos): 0.5153846153846153\n",
      "True ratio (OIPA) (Chronos): 1.0\n",
      "True ratio (ON) (Chronos): 0.09615384615384616\n",
      "True ratio (Confidence) (Real): 0.7653846153846153\n",
      "True ratio (Vote) (Real): 0.6884615384615385\n",
      "True ratio (minmax) (Real): 0.7653846153846153\n",
      "True ratio (OIPA) (Real): 0.8769230769230769\n",
      "True ratio (ON) (Real): 0.08461538461538462\n",
      "True ratio (Matching Vote): 0.3\n",
      "True ratio (Matching Confidence): 0.48846153846153845\n",
      "True ratio (Matching Minmax): 0.48846153846153845\n",
      "True ratio (Matching OIPA): 0.8769230769230769\n",
      "True ratio (Matching ON): 0.8346153846153846\n"
     ]
    }
   ],
   "source": [
    "# Majority Voting Ensemble Eval\n",
    "is_correct_confidence_chronos = []\n",
    "is_correct_vote_chronos = []\n",
    "is_correct_minmax_chronos = []\n",
    "is_correct_oipa_chronos = []\n",
    "is_correct_on_chronos = []\n",
    "is_correct_confidence_real = []\n",
    "is_correct_vote_real = []\n",
    "is_correct_minmax_real = []\n",
    "is_correct_oipa_real = []\n",
    "is_correct_on_real = []\n",
    "is_matching_vote = []\n",
    "is_matching_confidence = []\n",
    "is_matching_minmax = []\n",
    "is_matching_oipa = []\n",
    "is_matching_on = []\n",
    "\n",
    "# is_correct_vote = []\n",
    "# is_correct_minmax = []\n",
    "# is_correct_oipa = []\n",
    "# is_correct_on = []\n",
    "\n",
    "for i, (X_train, y_train) in enumerate(dataloader_chronos_layoffs_minmax):\n",
    "        # print(X_train)\n",
    "        # print(y_train)\n",
    "        # Forward pass\n",
    "    \n",
    "    X_train_minmax_chronos = dataloader_chronos_layoffs_minmax.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_oipa_chronos = dataloader_chronos_layoffs_oipa.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_on_chronos = dataloader_chronos_layoffs_on.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_minmax_real = dataloader_real_layoffs_minmax.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_oipa_real = dataloader_real_layoffs_oipa.dataset.X_train[i].unsqueeze(0).float()\n",
    "    X_train_on_real = dataloader_real_layoffs_on.dataset.X_train[i].unsqueeze(0).float()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # print(outputs_minmax)\n",
    "    outputs_minmax_chronos = model_minmax(X_train_minmax_chronos).squeeze(1)\n",
    "    outputs_oipa_chronos = model_open_inproportion_to_average(X_train_oipa_chronos).squeeze(1)\n",
    "    outputs_on_chronos = model_open_normalized(X_train_on_chronos).squeeze(1)\n",
    "    outputs_minmax_real = model_minmax(X_train_minmax_real).squeeze(1)\n",
    "    outputs_oipa_real = model_open_inproportion_to_average(X_train_oipa_real).squeeze(1)\n",
    "    outputs_on_real = model_open_normalized(X_train_on_real).squeeze(1)\n",
    "\n",
    "    \n",
    "\n",
    "    ## Ensemble confidence based on average of outputs\n",
    "    confidence_avg_out_chronos = ( outputs_minmax_chronos+ outputs_oipa_chronos) / 2\n",
    "    confidence_output_bin_chronos = (confidence_avg_out_chronos >= 0.5).int().item()\n",
    "    confidence_avg_out_real = ( outputs_minmax_real + outputs_oipa_real) / 2\n",
    "    confidence_output_bin_real = (confidence_avg_out_real >= 0.5).int().item()\n",
    "    \n",
    "    ## Ensemble voting based on majority voting\n",
    "    vote_minmax_chronos = (outputs_minmax_chronos >= 0.5).int().item()\n",
    "    is_correct_minmax_chronos.append(vote_minmax_chronos == int(1.0))\n",
    "    vote_oipa_chronos = (outputs_oipa_chronos >= 0.5).int().item()\n",
    "    is_correct_oipa_chronos.append(vote_oipa_chronos == int(1.0))\n",
    "    vote_on_chronos = (outputs_on_chronos >= 0.5).int().item()\n",
    "    is_correct_on_chronos.append(vote_on_chronos == int(1.0))\n",
    "    \n",
    "    vote_minmax_real = (outputs_minmax_real >= 0.5).int().item()\n",
    "    is_correct_minmax_real.append(vote_minmax_real == int(1.0))\n",
    "    vote_oipa_real = (outputs_oipa_real >= 0.5).int().item()\n",
    "    is_correct_oipa_real.append(vote_oipa_real == int(1.0))\n",
    "    vote_on_real = (outputs_on_real >= 0.5).int().item()\n",
    "    is_correct_on_real.append(vote_on_real == int(1.0))\n",
    "\n",
    "    ## Ensemble voting based on majority voting\n",
    "    vote_chronos = (vote_oipa_chronos + vote_on_chronos) >= 2\n",
    "    correct_confidence = confidence_output_bin_chronos == int(1.0)\n",
    "    correct_vote = vote_chronos == int(1.0)\n",
    "    is_correct_confidence_chronos.append(correct_confidence)\n",
    "    is_correct_vote_chronos.append(correct_vote)\n",
    "\n",
    "    vote_real = (vote_minmax_real + vote_oipa_real + vote_on_real) >= 2\n",
    "    correct_confidence_real = confidence_output_bin_real == int(1.0)\n",
    "    correct_vote_real = vote_real == int(1.0)\n",
    "    is_correct_confidence_real.append(correct_confidence_real)\n",
    "    is_correct_vote_real.append(correct_vote_real)\n",
    "\n",
    "    is_matching_vote.append(vote_chronos == vote_real)\n",
    "    is_matching_confidence.append(confidence_output_bin_chronos == confidence_output_bin_real)\n",
    "    is_matching_minmax.append(vote_minmax_chronos == vote_minmax_real)\n",
    "    is_matching_oipa.append(vote_oipa_chronos == vote_oipa_real)\n",
    "    is_matching_on.append(vote_on_chronos == vote_on_real)\n",
    "\n",
    "    # out = outputs.squeeze(1)\n",
    "    # output_bin = (out >= 0.5).int().item()\n",
    "    # correct = output_bin == int(y_train.item())\n",
    "    # is_correct.append(correct)\n",
    "# Count ratio of trues and falses in is_correct\n",
    "with open(\"outputs_layoffs_5.txt\", \"w\") as f:\n",
    "    chronos_f1_prepro_layoff = [0 if i == False else 1 for i in is_correct_confidence_chronos]\n",
    "    chronos_f1_true_layoff = [1 for i in is_correct_confidence_chronos]\n",
    "    # f1 = f1_score(chronos_f1_prepro, chronos_f1_true, pos_label=1, average=\"binary\")\n",
    "    # print(f\"F1 Score (Confidence) (Chronos): {f1}\")\n",
    "    # f.write(f\"F1 Score (Confidence) (Chronos): {f1}\\n\")\n",
    "    print(\"is correct real\", is_correct_confidence_real)\n",
    "    real_f1_prepro_layoff = [0 if i == False else 1 for i in is_correct_confidence_real]\n",
    "    real_f1_true_layoff = [1 for i in is_correct_confidence_real]\n",
    "    # f1 = f1_score(real_f1_prepro, real_f1_true, pos_label=1, average=\"binary\")\n",
    "    # print(f\"F1 Score (Confidence) (Real): {f1}\")\n",
    "    # f.write(f\"F1 Score (Confidence) (Real): {f1}\\n\")\n",
    "    true_count_confidence_chronos = sum(is_correct_confidence_chronos)\n",
    "    false_count_confidence_chronos = len(is_correct_confidence_chronos) - true_count_confidence_chronos\n",
    "    # print(f\"True count (Confidence) (Chronos): {true_count_confidence_chronos}\")\n",
    "    # print(f\"False count (Confidence) (Chronos): {false_count_confidence_chronos}\")\n",
    "    print(f\"True ratio (Confidence) (Chronos): {true_count_confidence_chronos / len(is_correct_confidence_chronos)}\")\n",
    "    f.write(f\"True ratio (Confidence) (Chronos): {true_count_confidence_chronos / len(is_correct_confidence_chronos)}\\n\")\n",
    "    true_count_vote_chronos = sum(is_correct_vote_chronos)\n",
    "    false_count_vote_chronos = len(is_correct_vote_chronos) - true_count_vote_chronos\n",
    "    # print(f\"True count (Vote) (Chronos): {true_count_vote_chronos}\")\n",
    "    # print(f\"False count (Vote) (Chronos): {false_count_vote_chronos}\")\n",
    "    print(f\"True ratio (Vote) (Chronos): {true_count_vote_chronos / len(is_correct_vote_chronos)}\")\n",
    "    f.write(f\"True ratio (Vote) (Chronos): {true_count_vote_chronos / len(is_correct_vote_chronos)}\\n\")\n",
    "    true_count_minmax_chronos = sum(is_correct_minmax_chronos)\n",
    "    false_count_minmax_chronos = len(is_correct_minmax_chronos) - true_count_minmax_chronos\n",
    "    # print(f\"True count (minmax) (Chronos): {true_count_minmax_chronos}\")\n",
    "    # print(f\"False count (minmax) (Chronos): {false_count_minmax_chronos}\")\n",
    "    print(f\"True ratio (minmax) (Chronos): {true_count_minmax_chronos / len(is_correct_minmax_chronos)}\")\n",
    "    f.write(f\"True ratio (minmax) (Chronos): {true_count_minmax_chronos / len(is_correct_minmax_chronos)}\\n\")\n",
    "    true_count_oipa_chronos = sum(is_correct_oipa_chronos)\n",
    "    false_count_oipa_chronos = len(is_correct_oipa_chronos) - true_count_oipa_chronos\n",
    "\n",
    "    print(f\"True ratio (OIPA) (Chronos): {true_count_oipa_chronos / len(is_correct_oipa_chronos)}\")\n",
    "    f.write(f\"True ratio (OIPA) (Chronos): {true_count_oipa_chronos / len(is_correct_oipa_chronos)}\\n\")\n",
    "    true_count_on_chronos = sum(is_correct_on_chronos)\n",
    "    false_count_on_chronos = len(is_correct_on_chronos) - true_count_on_chronos\n",
    "    print(f\"True ratio (ON) (Chronos): {true_count_on_chronos / len(is_correct_on_chronos)}\")\n",
    "    f.write(f\"True ratio (ON) (Chronos): {true_count_on_chronos / len(is_correct_on_chronos)}\\n\")\n",
    "\n",
    "\n",
    "    true_count_confidence_real = sum(is_correct_confidence_real)\n",
    "    false_count_confidence_real = len(is_correct_confidence_real) - true_count_confidence_real\n",
    "    # print(f\"True count (Confidence) (Real): {true_count_confidence_real}\")\n",
    "    # print(f\"False count (Confidence) (Real): {false_count_confidence_real}\")\n",
    "    print(f\"True ratio (Confidence) (Real): {true_count_confidence_real / len(is_correct_confidence_real)}\")\n",
    "    f.write(f\"True ratio (Confidence) (Real): {true_count_confidence_real / len(is_correct_confidence_real)}\\n\")\n",
    "    true_count_vote_real = sum(is_correct_vote_real)\n",
    "    false_count_vote_real = len(is_correct_vote_real) - true_count_vote_real\n",
    "    # print(f\"True count (Vote) (Real): {true_count_vote_real}\")\n",
    "    # print(f\"False count (Vote) (Real): {false_count_vote_real}\")\n",
    "    print(f\"True ratio (Vote) (Real): {true_count_vote_real / len(is_correct_vote_real)}\")\n",
    "    f.write(f\"True ratio (Vote) (Real): {true_count_vote_real / len(is_correct_vote_real)}\\n\")\n",
    "    true_count_minmax_real = sum(is_correct_minmax_real)\n",
    "    false_count_minmax_real = len(is_correct_minmax_real) - true_count_minmax_real\n",
    "    # print(f\"True count (minmax) (Real): {true_count_minmax_real}\")\n",
    "    # print(f\"False count (minmax) (Real): {false_count_minmax_real}\")\n",
    "    print(f\"True ratio (minmax) (Real): {true_count_minmax_real / len(is_correct_minmax_real)}\")\n",
    "    f.write(f\"True ratio (minmax) (Real): {true_count_minmax_real / len(is_correct_minmax_real)}\\n\")\n",
    "    true_count_oipa_real = sum(is_correct_oipa_real)\n",
    "    false_count_oipa_real = len(is_correct_oipa_real) - true_count_oipa_real\n",
    "    # print(f\"True count (OIPA) (Real): {true_count_oipa_real}\")\n",
    "    # print(f\"False count (OIPA) (Real): {false_count_oipa_real}\")\n",
    "    print(f\"True ratio (OIPA) (Real): {true_count_oipa_real / len(is_correct_oipa_real)}\")\n",
    "    f.write(f\"True ratio (OIPA) (Real): {true_count_oipa_real / len(is_correct_oipa_real)}\\n\")\n",
    "    true_count_on_real = sum(is_correct_on_real)\n",
    "    false_count_on_real = len(is_correct_on_real) - true_count_on_real\n",
    "    # print(f\"True count (ON) (Real): {true_count_on_real}\")\n",
    "    # print(f\"False count (ON) (Real): {false_count_on_real}\")\n",
    "    print(f\"True ratio (ON) (Real): {true_count_on_real / len(is_correct_on_real)}\")\n",
    "    f.write(f\"True ratio (ON) (Real): {true_count_on_real / len(is_correct_on_real)}\\n\")\n",
    "\n",
    "    true_count_matching_vote = sum(is_matching_vote)\n",
    "    false_count_matching_vote = len(is_matching_vote) - true_count_matching_vote\n",
    "    print(f\"True ratio (Matching Vote): {true_count_matching_vote / len(is_matching_vote)}\")\n",
    "    f.write(f\"True ratio (Matching Vote): {true_count_matching_vote / len(is_matching_vote)}\\n\")\n",
    "    true_count_matching_confidence = sum(is_matching_confidence)\n",
    "    false_count_matching_confidence = len(is_matching_confidence) - true_count_matching_confidence\n",
    "    print(f\"True ratio (Matching Confidence): {true_count_matching_confidence / len(is_matching_confidence)}\")\n",
    "    f.write(f\"True ratio (Matching Confidence): {true_count_matching_confidence / len(is_matching_confidence)}\\n\")\n",
    "    true_count_matching_minmax = sum(is_matching_minmax)\n",
    "    false_count_matching_minmax = len(is_matching_minmax) - true_count_matching_minmax\n",
    "    print(f\"True ratio (Matching Minmax): {true_count_matching_minmax / len(is_matching_minmax)}\")\n",
    "    f.write(f\"True ratio (Matching Minmax): {true_count_matching_minmax / len(is_matching_minmax)}\\n\")\n",
    "    true_count_matching_oipa = sum(is_matching_oipa)\n",
    "    false_count_matching_oipa = len(is_matching_oipa) - true_count_matching_oipa\n",
    "    print(f\"True ratio (Matching OIPA): {true_count_matching_oipa / len(is_matching_oipa)}\")\n",
    "    f.write(f\"True ratio (Matching OIPA): {true_count_matching_oipa / len(is_matching_oipa)}\\n\")\n",
    "    true_count_matching_on = sum(is_matching_on)\n",
    "    false_count_matching_on = len(is_matching_on) - true_count_matching_on\n",
    "    print(f\"True ratio (Matching ON): {true_count_matching_on / len(is_matching_on)}\")\n",
    "    f.write(f\"True ratio (Matching ON): {true_count_matching_on / len(is_matching_on)}\\n\")\n",
    "\n",
    "f.close()\n",
    "    # print(f\"True count (OIPA) (Chronos): {true_count_oipa_chronos}\")\n",
    "    # print(f\"False count (OIPA) (Chronos): {false_count_oipa_chronos}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# true_count_confidence = sum(is_correct_confidence)\n",
    "# false_count_confidence = len(is_correct_confidence) - true_count_confidence\n",
    "# print(f\"True count (Confidence): {true_count_confidence}\")\n",
    "# print(f\"False count (Confidence): {false_count_confidence}\")\n",
    "# print(f\"True ratio (Confidence): {true_count_confidence / len(is_correct_confidence)}\")\n",
    "# true_count_vote = sum(is_correct_vote)\n",
    "# false_count_vote = len(is_correct_vote) - true_count_vote\n",
    "# print(f\"True count (Vote): {true_count_vote}\")\n",
    "# print(f\"False count (Vote): {false_count_vote}\")\n",
    "# print(f\"True ratio (Vote): {true_count_vote / len(is_correct_vote)}\")\n",
    "# true_count_minmax = sum(is_correct_minmax)\n",
    "# false_count_minmax = len(is_correct_minmax) - true_count_minmax\n",
    "# print(f\"True count (minmax): {true_count_minmax}\")\n",
    "# print(f\"False count (minmax): {false_count_minmax}\")\n",
    "# print(f\"True ratio (minmax): {true_count_minmax / len(is_correct_minmax)}\")\n",
    "# true_count_oipa = sum(is_correct_oipa)\n",
    "# false_count_oipa = len(is_correct_oipa) - true_count_oipa\n",
    "# print(f\"True count (OIPA): {true_count_oipa}\")\n",
    "# print(f\"False count (OIPA): {false_count_oipa}\")\n",
    "# print(f\"True ratio (OIPA): {true_count_oipa / len(is_correct_oipa)}\")\n",
    "# true_count_on = sum(is_correct_on)\n",
    "# false_count_on = len(is_correct_on) - true_count_on\n",
    "# print(f\"True count (ON): {true_count_on}\")\n",
    "# print(f\"False count (ON): {false_count_on}\")\n",
    "# print(f\"True ratio (ON): {true_count_on / len(is_correct_on)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_chronos = f1_score(chronos_f1_prepro_nolayoff+chronos_f1_prepro_layoff, chronos_f1_true_nolayoff+chronos_f1_true_layoff, pos_label=1, average=\"binary\")\n",
    "f1_real = f1_score(real_f1_prepro_nolayoffs+real_f1_prepro_layoff, real_f1_true_nolayoffs+real_f1_true_layoff, pos_label=1, average=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4426877470355731"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6676096181046676"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count ratio of trues and falses in is_correct\n",
    "# true_count = sum(is_correct)\n",
    "# false_count = len(is_correct) - true_count\n",
    "# print(f\"True count: {true_count}\")\n",
    "# print(f\"False count: {false_count}\")\n",
    "# print(f\"True ratio: {true_count / len(is_correct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each model\n",
    "directory = \"classifier_models/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "torch.save(model_minmax.state_dict(), directory +\"minmax_model.pth\")\n",
    "torch.save(model_open_inproportion_to_average.state_dict(), directory +\"open_inproportion_to_average_model.pth\")\n",
    "torch.save(model_open_normalized.state_dict(), directory +\"open_normalized_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'classifier_models/open_inproportion_to_average_model_2.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model_open_normalized \u001b[38;5;241m=\u001b[39m BinaryClassifier()\n\u001b[0;32m      5\u001b[0m model_minmax\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(directory \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminmax_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m model_open_inproportion_to_average\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopen_inproportion_to_average_model_2.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m model_open_normalized\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(directory \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_normalized_model_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\alexs\\anaconda3\\envs\\cs828\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\alexs\\anaconda3\\envs\\cs828\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\alexs\\anaconda3\\envs\\cs828\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'classifier_models/open_inproportion_to_average_model_2.pth'"
     ]
    }
   ],
   "source": [
    "# Load in saved models\n",
    "model_minmax = BinaryClassifier()\n",
    "model_open_inproportion_to_average = BinaryClassifier()\n",
    "model_open_normalized = BinaryClassifier()\n",
    "model_minmax.load_state_dict(torch.load(directory +\"minmax_model.pth\"))\n",
    "model_open_inproportion_to_average.load_state_dict(torch.load(directory +\"open_inproportion_to_average_model_2.pth\"))\n",
    "model_open_normalized.load_state_dict(torch.load(directory +\"open_normalized_model_2.pth\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs828",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
